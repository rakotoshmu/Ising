\documentclass[a4paper,11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
% \usepackage{fullpage}
\usepackage{amsmath, amsfonts, amssymb, amsthm}
% \usepackage{mathabx}
% \usepackage{bbm}
\usepackage{stmaryrd}
% \usepackage{enumerate}

\input{preamble_Macro}

\title{Projet de simulations aléatoires : Modèles d'Ising}
\author{Aurélien Enfroy, Shmuel Rakotonirina{-}-Ricquebourg}

\begin{document}
\maketitle

\section{Implémentation du modèle d'Ising}

On rappelle la définition du modèle d'Ising sur un réseau carré :
\begin{definition}
On fixe $C$ le réseau carré de dimension 2 de taille $N^2$. Le modèle d'Ising est la distribution sur l'espace d'état $\set{\pm 1}^C$ dont la loi est donnée par
$$\forall x \in \set{\pm 1}^C, \pi(x) = \frac{1}{Z_T} \exp \left(\left( \somme{u\sim v}{} J_{u,v} x_{u} x_{v} + \somme{u}{} h_{u} x_{u} \right)/T\right)$$
où $T>0$ est appelée la température, $Z_T$ est une constante de normalisation, $J_{u,v}$ est la force d'interaction entre $u$ et $v$ et $h_{u}$ est le champ magnétique extérieur en $u$.
\end{definition}

Pour l'implémentation, on remarque qu'il n'y a pas besoin du paramètre $T$, qu'on peut compter dans $J$ et $h$. On représente alors ces paramètres en prenant $x \in \mathcal M_{N,N}(\set{\pm 1})$, $h \in \mathcal M_{N,N}(\mathbb R)$ et $J$ comme une matrice à trois entrées $\tilde J \in \mathcal M_{N,N,2}(\mathbb R)$ où
$$\tilde J_{i,j,1} = J_{(i,j),(i+1,j)} \text{ et } \tilde J_{i,j,2} = J_{(i,j),(i,j+1)}.$$

\section{Simulation naïve en petite taille}

En petite taille, on peut faire une simulation naïve. Pour cela, on numérote les $2^{N^2}$ états (dans l'ordre lexicographique en lisant les matrices colonne par colonne), on calcule exactement la loi et on choisit un numéro en utilisant cette loi et une loi uniforme sur $[0,1]$.

\section{Simulation par Metropolis-Hastings}\label{sec:MH}

Nous avons implémenté l'algorithme de Metropolis-Hastings en utilisant la fonction de rejet de Metropolis-Hastings. Pour le choix du noyau instrumental $Q$, nous avons choisi de donner à une coordonnée aléatoire (uniforme) une valeur aléatoire (uniforme), ce qui permet d'avoir un noyau symétrique irréductible apériodique (probabilité strictement positive de rester sur place).

Avec ce noyau instrumental, on peut réduire les calculs effectués : si $x$ est un état et $y$ l'état proposé à partir de $x$, alors
\begin{itemize}
	\item soit $y = x$, auquel cas on peut considérer qu'on accepte le mouvement,
	\item soit $y \neq x$, auquel cas ils ne diffèrent que d'au plus une coordonnée (celle tirée uniformément). Si on note $u$ cette coordonnée et $s$ la nouvelle valeur, alors $s = y_u = - x_u$ et, en considérant que $T$ a été pris en compte dans $J$ et $h$,
	\begin{align*}
	\frac{\pi(y)}{\pi(x)}
	&= \frac{\exp \left( \somme{v \sim u}{} J_{u,v} s x_{v} + h_{u} s \right)}{\exp \left( \somme{v \sim u}{} J_{u,v} (-s) x_{v} + h_{u} (-s) \right)}\\
	&= \frac{e^{s V_u(x)}}{e^{-s V_u(x)}}\\
	&= e^{2 s V_u(x)}
	\end{align*}
	où on a noté $V_u(x) \doteq \somme{v \sim u}{} J_{u,v} x_v + h_u$.
\end{itemize}

\section{Simulation par l'échantilloneur de Gibbs}

En reprenant les notations du cours, on a pour $u \in C$ et $x \in \set{\pm 1}^C$, en considérant que $J$ et $h$ dépendent de $T$,
\begin{align*}
\pi_u(x_u \mid x^u)
&= \frac{\pi(x_u,x^u)}{\pi(1,x^u) + \pi(-1,x^u)}\\
&= \frac{e^{x_u V_u(x)}}{e^{V_u(x)} + e^{-V_u(x)}}
\end{align*}
où on note encore $V_u(x) \doteq \somme{v \sim u}{} J_{u,v} x_v + h_u$. Donc $\pi_u(\cdot \mid x^u) = \mathcal B(\frac{e^{V_u(x)}}{e^{V_u(x)} + e^{-V_u(x)}}) = B(\frac{1}{1 + e^{-2V_u(x)}})$

\section{Couplage par le passé}

Pour le couplage par le passé, deux fonctions d'actualisation sont possibles. Celle vue en cours est celle issue de l'échantillonneur de Gibbs (par balayage séquentiel). L'autre, présente dans le livre de Propp-Wilson, est issue de l'algorithme de Metropolis-Hastings (i.e. même transition qu'en section \ref{sec:MH}).

Dans les deux cas, les choses se passent bien au-delà de la température critique. Cependant, en dessous de la température critique, les états $\pm(1,\hdots,1)$ ont tendance à rester inchangés par les fonctions d'actualisation précédentes : dans les deux cas, la probabilité de réussir à changer un point $x_u$ égaux à ses quatre voisins est très faible : pour $J/T = \alpha$ constant, $h = 0$, elle vaut $\exp(-8 \alpha)$.

En conséquence, l'algorithme met extrêmement longtemps à terminer (nous n'avons pas vu terminer). En observant l'évolution des chaînes de Markov (parties de $(1,\hdots,1)$ et de $(-1,\hdots,-1)$, on voit que souvent les deux chaînes reviennent à leur état initial, ce qui signifie que tout ce qui a été simulé jusqu'ici a été une perte de temps.

\end{document}